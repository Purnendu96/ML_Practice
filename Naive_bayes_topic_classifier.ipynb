{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Topic Classifier<br>MDS201803<br>MDS201811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data as one string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=''\n",
    "for i in list(range(0,22)):\n",
    "    if i<10:\n",
    "        fl_name=r\"C:/Users/LENOVO/Downloads/reuters21578/reut2-00\"+str(0+i)+\".sgm\"\n",
    "    else:\n",
    "        fl_name=r\"C:/Users/LENOVO/Downloads/reuters21578/reut2-0\"+str(0+i)+\".sgm\"\n",
    "    with open(fl_name,\"r\") as f:\n",
    "        ls = ls + f.read()   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the news Body using regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "body=[]\n",
    "r=re.compile(r\"<REUTERS([\\S\\s]*?)</TEXT>\")\n",
    "b_1=re.compile(r\"<BODY>([\\S\\s]*?)</BODY>\")\n",
    "b_2=re.compile(r\"<TITLE>([\\S\\s]*?)</TITLE>\")\n",
    "b_3=re.compile(r\"&#2;([\\S\\s]*?)&#3;\")\n",
    "t_1=re.compile(r\"<TEXT>\")\n",
    "t_2=re.compile(r'''<TEXT TYPE=\"BRIEF\">''')\n",
    "n=r.findall(ls)\n",
    "for x in n:\n",
    "    if t_1.findall(x)!=[]:\n",
    "        body.append(b_1.findall(x))\n",
    "    elif t_2.findall(x)!=[]:\n",
    "        body.append(b_2.findall(x))\n",
    "    else:\n",
    "        body.append(b_3.findall(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Topics of news articles using regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic=[]\n",
    "import re\n",
    "p=re.compile(r\"<TOPICS(>[<D>(\\S)</D>]*<)/TOPICS>\")\n",
    "q=re.compile(r\"<D>([\\w-]*)</D>\")\n",
    "m = p.findall(ls)\n",
    "for x in m:\n",
    "    if x=='><':\n",
    "        topic.append([\"None\"])\n",
    "    else:\n",
    "        topic.append(q.findall(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting predefined Type(Train-Test) of news article using regular expression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test=[]\n",
    "l=re.compile(r'''CGISPLIT=([\\w\"-]*)''')\n",
    "train_test=l.findall(ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following code excludes all news articles from the dataframe which have assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=[i for i,val in enumerate(topic) if val==['None'] ]\n",
    "topic1 = topic[:]\n",
    "for i in indices:\n",
    "    topic.remove(topic1[i]) \n",
    "body1=body[:]\n",
    "for i in indices:\n",
    "    body.remove(body1[i])               \n",
    "train_test1=train_test[:]\n",
    "for i in indices:\n",
    "    train_test.remove(train_test1[i])     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The function preprocess_string does the following:\n",
    "<br>        1. everything apart from letters is excluded\n",
    "<br>         2. multiple spaces are replaced by single space\n",
    "<br>         3. str_arg is converted to lower case  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(str_arg):\n",
    "    cleaned_str=re.sub('[^a-z\\s]+',' ',str_arg,flags=re.IGNORECASE) #every char except alphabets is replaced\n",
    "    cleaned_str=re.sub('(\\s+)',' ',cleaned_str) #multiple spaces are replaced by single space\n",
    "    cleaned_str=cleaned_str.lower() #converting the cleaned string to lower case\n",
    "    return cleaned_str # returning the preprocessed string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Body=[]\n",
    "for i in range(len(body)):\n",
    "    Body.append((preprocess_string(body[i][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuples=list(zip(topic,Body,train_test))\n",
    "df = pd.DataFrame(df_tuples, columns = ['Topics', 'Body', 'Train_test']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following function replicates a news body corresponding to each assigned topics to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode(df, lst_cols, fill_value='', preserve_index=False):\n",
    "    # make sure `lst_cols` is list-alike\n",
    "    if (lst_cols is not None\n",
    "        and len(lst_cols) > 0\n",
    "        and not isinstance(lst_cols, (list, tuple, np.ndarray, pd.Series))):\n",
    "        lst_cols = [lst_cols]\n",
    "    # all columns except `lst_cols`\n",
    "    idx_cols = df.columns.difference(lst_cols)\n",
    "    # calculate lengths of lists\n",
    "    lens = df[lst_cols[0]].str.len()\n",
    "    # preserve original index values    \n",
    "    idx = np.repeat(df.index.values, lens)\n",
    "    # create \"exploded\" DF\n",
    "    res = (pd.DataFrame({\n",
    "                col:np.repeat(df[col].values, lens)\n",
    "                for col in idx_cols},\n",
    "                index=idx)\n",
    "             .assign(**{col:np.concatenate(df.loc[lens>0, col].values)\n",
    "                            for col in lst_cols}))\n",
    "    # append those rows that have empty lists\n",
    "    if (lens == 0).any():\n",
    "        # at least one list in cells is empty\n",
    "        res = (res.append(df.loc[lens==0, idx_cols], sort=False)\n",
    "                  .fillna(fill_value))\n",
    "    # revert the original index order\n",
    "    res = res.sort_index()\n",
    "    # reset index if requested\n",
    "    if not preserve_index:        \n",
    "        res = res.reset_index(drop=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14302"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rep=explode(df,[\"Topics\"], fill_value='', preserve_index=True)\n",
    "len(df_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following code assigns unique numeric labels to each of the topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "leb=LabelEncoder()\n",
    "df_rep[\"Topic_Encoded\"]=leb.fit_transform(df_rep['Topics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test train split of data according to predefined lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Topic_train = df_rep[df_rep['Train_test']== '\"TRAINING-SET\"'][\"Topic_Encoded\"] \n",
    "Topic_test = df_rep[df_rep['Train_test']!= '\"TRAINING-SET\"'][\"Topic_Encoded\"] \n",
    "Body_train = df_rep[df_rep['Train_test']== '\"TRAINING-SET\"'][\"Body\"] \n",
    "Body_test = df_rep[df_rep['Train_test']!= '\"TRAINING-SET\"'][\"Body\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test train split of data according to random allocation (80:20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X is (14302,)\n",
      "Shape of X_train is (10726,) and shape of y_train is (10726,)\n",
      "Shape of X_test is (3576,) and shape of y_test is (3576,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_rep['Body']\n",
    "y = df_rep['Topic_Encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=17)\n",
    "\n",
    "print(\"Shape of X is {}\".format(X.shape))\n",
    "print(\"Shape of X_train is {} and shape of y_train is {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Shape of X_test is {} and shape of y_test is {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we use tfidf vectorizer to give more weightage to  relevant words in the news document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes\n",
    "#### The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_bayes = Pipeline([('vectorizer', TfidfVectorizer()),('classifier', naive_bayes)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic_train,Body_train and Topic_test,Body_test are respectively training and testing datasets which are already defined as in the Reuters documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_bayes.fit(Body_train, Topic_train)\n",
    "label_predicted = pipeline_bayes.predict(Body_test) #Prediction on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4206989247311828\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of the model using Multinomial Naive Bayes. \n",
    "\n",
    "accuracy = accuracy_score(Topic_test, label_predicted)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X_train,y_train and X_test,y_test are respectively training and testing datasets which are generated random allocation (80:20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_bayes.fit(X_train, y_train) #Fitting the multinomial model to training data.\n",
    "label_predicted = pipeline_bayes.predict(X_test) #testing on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.38814317673378074\n"
     ]
    }
   ],
   "source": [
    "#Accuracy using multinomial naive bayes\n",
    "\n",
    "accuracy = accuracy_score(y_test, label_predicted)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complement Naive Bayes\n",
    "#### The Complement Naive Bayes classifier was designed to correct the “severe assumptions” made by the standard Multinomial Naive Bayes classifier. It is particularly suited for imbalanced data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "naive_bayes_c = ComplementNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_bayes_c = Pipeline([('vectorizer', TfidfVectorizer()),('classifier', naive_bayes_c)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic_train,Body_train and Topic_test,Body_test are respectively training and testing datasets which are already defined as in the Reuters documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_bayes_c.fit(Body_train, Topic_train)\n",
    "label_predicted = pipeline_bayes_c.predict(Body_test) #Prediction on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.646505376344086\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of the model using Multinomial Naive Bayes. \n",
    "\n",
    "accuracy = accuracy_score(Topic_test, label_predicted)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X_train,y_train and X_test,y_test are respectively training and testing datasets which are generated random allocation (80:20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_bayes_c.fit(X_train, y_train) #Fitting the multinomial model to training data.\n",
    "label_predicted = pipeline_bayes_c.predict(X_test) #testing on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.47175615212527966\n"
     ]
    }
   ],
   "source": [
    "#Accuracy using multinomial naive bayes\n",
    "\n",
    "accuracy = accuracy_score(y_test, label_predicted)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
